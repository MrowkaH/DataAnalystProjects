{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ee612e-c8f1-472f-b62d-dfdce02ce80e",
   "metadata": {},
   "source": [
    "# Wczytwyanie danych i bazy danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367d98b-b944-49d4-aa2c-e956742ccfb9",
   "metadata": {},
   "source": [
    "**Zadanie 1**\n",
    "Przeanalizuj plik `dane6.csv` iterując po nim w porcjach po `1000` wierszy.\n",
    "\n",
    "Na podstawie wartości w kolumnie `key` wykonaj agregację liczby wystąpień poszczególnych wartości tej kolumny. Po przetworzeniu całego pliku zwróć zestawienie (`key` $\\to$ liczba wystąpień), posortowane malejąco po liczbie wystąpień.\n",
    "\n",
    "Uwaga: rozwiązanie powinno działać strumieniowo - nie wolno jednorazowo wczytywać całego pliku do pamięci.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d857cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 411),\n",
       " ('M', 410),\n",
       " ('J', 407),\n",
       " ('O', 399),\n",
       " ('L', 398),\n",
       " ('K', 398),\n",
       " ('C', 395),\n",
       " ('U', 392),\n",
       " ('Z', 391),\n",
       " ('P', 391)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "BATCH = 1000\n",
    "key_counts = Counter()\n",
    "\n",
    "for part in pd.read_csv(r'data\\dane6.csv', chunksize=BATCH):\n",
    "    part_counts = part['key'].value_counts().to_dict()\n",
    "    key_counts.update(part_counts)\n",
    "\n",
    "final_res = sorted(key_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "final_res[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731b488-cf09-427f-883e-50fda8a8b4e1",
   "metadata": {},
   "source": [
    "**Zadanie 2**\n",
    "Korzystając z funkcji `read_html()` pakietu `pandas` wczytaj tabele z polskiej strony Wikipedii dot. Krakowa. Znadź tabelę zawirającą średnia temperatura i opady dla Krakowa. Usuń soatni wiersz tej tabeli a kolumne z rocznym podsumowanie zastąp poprawnie na nowo wyliczonymi wartosciami (dlaczego ta kolumna we wczytanej tabeli zawiara błędne dane?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dd0b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m wiki_link = \u001b[33m'\u001b[39m\u001b[33mhttps://pl.wikipedia.org/wiki/Krak\u001b[39m\u001b[33m%\u001b[39m\u001b[33mC3\u001b[39m\u001b[33m%\u001b[39m\u001b[33mB3w\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dfs = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwiki_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m weather_df = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dfs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:983\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m p = parser(\n\u001b[32m    973\u001b[39m     io,\n\u001b[32m    974\u001b[39m     compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m     storage_options,\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     tables = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[32m    986\u001b[39m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[33m\"\u001b[39m\u001b[33mseekable\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io.seekable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:249\u001b[39m, in \u001b[36m_HtmlFrameParser.parse_tables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     tables = \u001b[38;5;28mself\u001b[39m._parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.match, \u001b[38;5;28mself\u001b[39m.attrs)\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:806\u001b[39m, in \u001b[36m_LxmlFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    804\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[33m\"\u001b[39m\u001b[33mtext_content\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:785\u001b[39m, in \u001b[36m_LxmlFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m.io):\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    788\u001b[39m             r = parse(f.handle, parser=parser)\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    790\u001b[39m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wiki_link = 'https://pl.wikipedia.org/wiki/Krak%C3%B3w'\n",
    "dfs = pd.read_html(wiki_link)\n",
    "\n",
    "weather_df = None\n",
    "for df in dfs:\n",
    "    cols_str = ''.join([str(c) for c in df.columns])\n",
    "    if 'Średnia temperatura' in cols_str or 'Opady' in cols_str:\n",
    "        weather_df = df\n",
    "        break\n",
    "\n",
    "weather_df = weather_df.iloc[:-1].copy().reset_index(drop=True)\n",
    "\n",
    "t_cols = [c for c in weather_df.columns if '°C' in str(c)]\n",
    "p_cols = [c for c in weather_df.columns if 'mm' in str(c)]\n",
    "\n",
    "if t_cols:\n",
    "    weather_df['Średnia roczna temperatura'] = weather_df[t_cols].astype(float).mean(axis=1)\n",
    "\n",
    "if p_cols:\n",
    "    weather_df['Suma roczna opadów'] = weather_df[p_cols].astype(float).sum(axis=1)\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967e8e0-51ae-49f6-b848-63599706498a",
   "metadata": {},
   "source": [
    "**Zadanie 3**\n",
    "Na podstawie wykładu i zbioru plików danych (*database*) utwórz na ramki danych oraz baze danych z tabelami na podstawi tych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873c22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          engine                      type\n",
       " 0        4 Cycle  Fixed wing single engine\n",
       " 1  Reciprocating   Fixed wing multi engine\n",
       " 2  Reciprocating  Fixed wing single engine\n",
       " 3      Turbo-fan   Fixed wing multi engine\n",
       " 4      Turbo-jet   Fixed wing multi engine,\n",
       "           engine                      type\n",
       " 0        4 Cycle  Fixed wing single engine\n",
       " 1  Reciprocating   Fixed wing multi engine\n",
       " 2  Reciprocating  Fixed wing single engine\n",
       " 3      Turbo-fan   Fixed wing multi engine\n",
       " 4      Turbo-jet   Fixed wing multi engine)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "planes = pd.read_csv(r'database\\planes.csv')\n",
    "flights = pd.read_csv(r'database\\flights.csv')\n",
    "airports = pd.read_csv(r'database\\airports.csv')\n",
    "weather = pd.read_csv(r'database\\weather.csv')\n",
    "engine = create_engine('sqlite:///lab5_new.db')\n",
    "\n",
    "planes.to_sql('planes', engine, if_exists='replace', index=False)\n",
    "flights.to_sql('flights', engine, if_exists='replace', index=False)\n",
    "airports.to_sql('airports', engine, if_exists='replace', index=False)\n",
    "weather.to_sql('weather', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f9137-8fde-411f-9c87-3713ac3478f4",
   "metadata": {},
   "source": [
    "**W kolejnych zadaniach wykorzystaj dane utworzone po wykonaniu zadania 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738e072-6a53-4ad5-a3f0-fd3a77dc473b",
   "metadata": {},
   "source": [
    "\n",
    "**Zadanie 4**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Kolumna `engine` w tabeli `planes` określa typ silnika - jeden typ może występować w wielu samolotach. Wypisz dostępne i unikatowe typy silników, posortowane alfabetycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          engine     n\n",
       " 0        4 Cycle     2\n",
       " 1  Reciprocating    28\n",
       " 2      Turbo-fan  2750\n",
       " 3      Turbo-jet   535\n",
       " 4     Turbo-prop     2,\n",
       "           engine     n\n",
       " 0        4 Cycle     2\n",
       " 1  Reciprocating    28\n",
       " 2      Turbo-fan  2750\n",
       " 3      Turbo-jet   535\n",
       " 4     Turbo-prop     2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT DISTINCT engine FROM planes ORDER BY engine\")\n",
    "    res_sql_4 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_4 = planes['engine'].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "\n",
    "res_sql_4.head(), res_pd_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05700610-39b0-49d6-9adb-6f0c0d397b45",
   "metadata": {},
   "source": [
    "**Zadanie 5**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Zmienna `type` określa typ samolotu. Wybierz wszystkie unikatowe pary postaci: `engine`, `type`, posortowane alfabetycznie - najpierw po `engine`, potem po `type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT DISTINCT engine, type FROM planes ORDER BY engine, type\")\n",
    "    res_sql_5 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_5 = planes[['engine', 'type']].drop_duplicates().sort_values(['engine', 'type']).reset_index(drop=True)\n",
    "\n",
    "res_sql_5.head(), res_pd_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba091cf5-f924-4b9d-bb45-b9aa48ff52b5",
   "metadata": {},
   "source": [
    "**Zadanie 6**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "Dla każdego typu silnika oblicz w ilu samolotach został on zamontowany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       manufacturer    n\n",
       " 0            AIRBUS   66\n",
       " 1  AIRBUS INDUSTRIE    4\n",
       " 2            BOEING  225,\n",
       "        manufacturer    n\n",
       " 0            AIRBUS   66\n",
       " 1  AIRBUS INDUSTRIE    4\n",
       " 2            BOEING  225)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT engine, COUNT(*) as count FROM planes GROUP BY engine\")\n",
    "    res_sql_6 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_6 = planes.groupby('engine').size().reset_index(name='count')\n",
    "\n",
    "res_sql_6.head(), res_pd_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a781271-6973-4fe6-8a2d-9dedd429fbbe",
   "metadata": {},
   "source": [
    "**Zadanie 7**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "W tabeli `planes` wyznacz okresy produkcji samolotów w podgrupach określonych przez unikatowe pary (`engine`, `type`). Dla każdej pary oblicz `min(year)` jako rok najstarszej konstrukcji oraz `max(year)` jako rok najmłodszej konstrukcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9903af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine</th>\n",
       "      <th>type</th>\n",
       "      <th>min_year</th>\n",
       "      <th>max_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 Cycle</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>1980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>Fixed wing single engine</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turbo-fan</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turbo-jet</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          engine                      type  min_year  max_year\n",
       "0        4 Cycle  Fixed wing single engine    1975.0    1975.0\n",
       "1  Reciprocating   Fixed wing multi engine    1956.0    1980.0\n",
       "2  Reciprocating  Fixed wing single engine    1959.0    2007.0\n",
       "3      Turbo-fan   Fixed wing multi engine    1965.0    2013.0\n",
       "4      Turbo-jet   Fixed wing multi engine    1974.0    2005.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT engine, type, MIN(year) as min_y, MAX(year) as max_y\n",
    "        FROM planes\n",
    "        GROUP BY engine, type\n",
    "    \"\"\")\n",
    "    res_sql_7 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_7 = (\n",
    "    planes.groupby(['engine', 'type'])['year']\n",
    "    .agg(min_y='min', max_y='max')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "res_sql_7.head(), res_pd_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545db9d-7a89-4bc0-ac4f-6af1f1d55a92",
   "metadata": {},
   "source": [
    "**Zadanie 8**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wybierz wszystkie obserwacje z tabeli `planes`, dla których wartości zmiennej `speed` nie są brakami danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fa589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM planes WHERE speed IS NOT NULL\")\n",
    "    res_sql_8 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_8 = planes.loc[planes['speed'].notnull()]\n",
    "\n",
    "res_sql_8.head(), res_pd_8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf00b46-2f30-4297-9f43-3f49be9acde4",
   "metadata": {},
   "source": [
    "**Zadanie 9**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wybierz wszystkie wartości zmiennej `tailnum` z tabeli `planes` dla tych obserwacji, w których wartości zmiennej `year` są większe lub równe `2010`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT tailnum FROM planes WHERE year >= 2010\")\n",
    "    res_sql_9 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_9 = planes[planes['year'] >= 2010]['tailnum']\n",
    "\n",
    "res_sql_9.head(), res_pd_9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baffd41c-d476-4db6-99a9-c6625581cf66",
   "metadata": {},
   "source": [
    "**Zadanie 10**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Odczytaj `10` początkowych rekordów z tabeli `planes` odpowiadających liczbie siedzeń (`seats`) większej lub równej `100` oraz jednocześnie mniejszej lub równej `200`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137ab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0 tailnum    year                     type      manufacturer  \\\n",
       " 0           2  N102UW  1998.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 1           3  N103US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 2           4  N104UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 3           6  N105UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 4           7  N107US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 5           8  N108UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 6           9  N109UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 7          10  N110UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 8          34  N111US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 9          35  N11206  2000.0  Fixed wing multi engine            BOEING   \n",
       " \n",
       "       model  engines  seats speed     engine  \n",
       " 0  A320-214        2    182  None  Turbo-fan  \n",
       " 1  A320-214        2    182  None  Turbo-fan  \n",
       " 2  A320-214        2    182  None  Turbo-fan  \n",
       " 3  A320-214        2    182  None  Turbo-fan  \n",
       " 4  A320-214        2    182  None  Turbo-fan  \n",
       " 5  A320-214        2    182  None  Turbo-fan  \n",
       " 6  A320-214        2    182  None  Turbo-fan  \n",
       " 7  A320-214        2    182  None  Turbo-fan  \n",
       " 8  A320-214        2    182  None  Turbo-fan  \n",
       " 9   737-824        2    149  None  Turbo-fan  ,\n",
       "     Unnamed: 0 tailnum    year                     type      manufacturer  \\\n",
       " 1            2  N102UW  1998.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 2            3  N103US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 3            4  N104UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 5            6  N105UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 6            7  N107US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 7            8  N108UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 8            9  N109UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 9           10  N110UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 33          34  N111US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   \n",
       " 34          35  N11206  2000.0  Fixed wing multi engine            BOEING   \n",
       " \n",
       "        model  engines  seats  speed     engine  \n",
       " 1   A320-214        2    182    NaN  Turbo-fan  \n",
       " 2   A320-214        2    182    NaN  Turbo-fan  \n",
       " 3   A320-214        2    182    NaN  Turbo-fan  \n",
       " 5   A320-214        2    182    NaN  Turbo-fan  \n",
       " 6   A320-214        2    182    NaN  Turbo-fan  \n",
       " 7   A320-214        2    182    NaN  Turbo-fan  \n",
       " 8   A320-214        2    182    NaN  Turbo-fan  \n",
       " 9   A320-214        2    182    NaN  Turbo-fan  \n",
       " 33  A320-214        2    182    NaN  Turbo-fan  \n",
       " 34   737-824        2    149    NaN  Turbo-fan  )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT * FROM planes\n",
    "        WHERE seats >= 100 AND seats <= 200\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    res_sql_10 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_10 = planes[(planes['seats'] >= 100) & (planes['seats'] <= 200)].head(10)\n",
    "\n",
    "res_sql_10, res_pd_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a59efa-1f6d-4e9a-b022-bc7229de6a1f",
   "metadata": {},
   "source": [
    "**Zadanie 11**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wybierz samoloty o liczbie siedzeń większej lub równej `379`, które zostały wyprodukowane przez firmy `BOEING` lub `AIRBUS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM planes WHERE seats >= 379 AND (manufacturer = 'BOEING' OR manufacturer = 'AIRBUS')\")\n",
    "    res_sql_11 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_11 = planes.query(\"seats >= 379 and manufacturer in ['BOEING', 'AIRBUS']\")\n",
    "\n",
    "res_sql_11.head(), res_pd_11.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d83a3-bffb-48d0-9e97-112f23e72c18",
   "metadata": {},
   "source": [
    "**Zadanie 12**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Dla każdego producenta policz, ile wyprodukował samolotów o liczbie siedzeń większej niż `200`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e784e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (816652160.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msql_result_12.head()pandas_result_12.head()\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT manufacturer, COUNT(*) as count FROM planes WHERE seats > 200 GROUP BY manufacturer\")\n",
    "    res_sql_12 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_12 = planes[planes['seats'] > 200]['manufacturer'].value_counts().reset_index()\n",
    "res_pd_12.columns = ['manufacturer', 'count']\n",
    "\n",
    "res_sql_12.head(), res_pd_12.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539faf46-de80-426c-8709-8c883ab98bc9",
   "metadata": {},
   "source": [
    "**Zadanie 13**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wybierz tylko tych producentów, którzy wyprodukowali więcej niż `10` samolotów wyposażonych w więcej niż `200` siedzeń."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f09c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT manufacturer, COUNT(*) as count\n",
    "        FROM planes\n",
    "        WHERE seats > 200\n",
    "        GROUP BY manufacturer\n",
    "        HAVING count > 10\n",
    "    \"\"\")\n",
    "    res_sql_13 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "temp = planes[planes['seats'] > 200].groupby('manufacturer').size()\n",
    "res_pd_13 = temp[temp > 10].reset_index(name='count')\n",
    "\n",
    "res_sql_13.head(), res_pd_13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0458eb-d4c2-4546-8ea6-31d28e896486",
   "metadata": {},
   "source": [
    "**Zadanie 14**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wyznacz trzech najbardziej produktywnych producentów samolotów, rozumianych jako tych z największą liczbą rekordów w tabeli `planes`. Zwróć `3` producentów o najwyższych wartościach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT manufacturer, COUNT(*) as count\n",
    "        FROM planes\n",
    "        GROUP BY manufacturer\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 3\n",
    "    \"\"\")\n",
    "    res_sql_14 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_14 = planes['manufacturer'].value_counts().head(3).reset_index()\n",
    "res_pd_14.columns = ['manufacturer', 'count']\n",
    "\n",
    "res_sql_14, res_pd_14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4020a8-f6af-4aae-b3cc-5eb71b77e96a",
   "metadata": {},
   "source": [
    "**Zadanie 15**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wybierz wszystkie samoloty wyprodukowane przed `1970`. Uzyskane wyniki posortuj rosnąco względem `year` oraz `seats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM planes WHERE year < 1970 ORDER BY year, seats\")\n",
    "    res_sql_15 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_15 = planes.query(\"year < 1970\").sort_values(['year', 'seats'])\n",
    "\n",
    "res_sql_15.head(), res_pd_15.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b45f68-fbc4-4a66-a346-5b0c39af2492",
   "metadata": {},
   "source": [
    "**Zadanie 16**\n",
    "Przypomnij sobie informacje na temat operacji teoriomnogościowych w bazach danych, takich jak: suma (w SQL to `UNION`), iloczyn (w SQL to `INTERSECT`) oraz różnica (w SQL to `EXCEPT`) dwóch zbiorów.\n",
    "\n",
    "Ponadto, zdefiniuj dwie dodatkowe ramki danych:\n",
    "\n",
    "```python\n",
    "A = planes.iloc[planes.year.values < 1960, 0:4].reset_index(drop=True)\n",
    "B = planes.iloc[(planes.year.values >= 1959) & (planes.year.values <= 1963), 0:4].reset_index(drop=True)\n",
    "```\n",
    "Na podstawie wyżej zdefiniowanych ramek `A` i `B` dodaj tabele do bazy danych o takich samych nazwach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definicja ramek\n",
    "df_A = planes.iloc[planes['year'].values < 1960, :4].reset_index(drop=True)\n",
    "df_B = planes.iloc[(planes['year'].values >= 1959) & (planes['year'].values <= 1963), :4].reset_index(drop=True)\n",
    "\n",
    "# Zapis do bazy\n",
    "df_A.to_sql('A', con=engine, if_exists='replace', index=False)\n",
    "df_B.to_sql('B', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "df_A.head(), df_B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c7caa-515e-4cbe-a922-14913bcd0921",
   "metadata": {},
   "source": [
    "**Zadanie 17**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wyznacz sumę tabel `A` i `B` (z usuwaniem duplikatów). Następnie wyznacz sumę tabel `A` i `B`, ale bez usuwania duplikatów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f262ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query_union = text(\"SELECT * FROM A UNION SELECT * FROM B\")\n",
    "    res_sql_17_u = pd.read_sql(query_union, conn)\n",
    "    \n",
    "    query_union_all = text(\"SELECT * FROM A UNION ALL SELECT * FROM B\")\n",
    "    res_sql_17_ua = pd.read_sql(query_union_all, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_17_u = pd.concat([df_A, df_B]).drop_duplicates().reset_index(drop=True)\n",
    "res_pd_17_ua = pd.concat([df_A, df_B]).reset_index(drop=True)\n",
    "\n",
    "res_sql_17_u.shape, res_pd_17_u.shape, res_sql_17_ua.shape, res_pd_17_ua.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce3f02-3542-499c-8ba5-5546745aeef5",
   "metadata": {},
   "source": [
    "**Zadanie 18**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wyznacz iloczyn (część wspólną) tabel `A` i `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM A INTERSECT SELECT * FROM B\")\n",
    "    res_sql_18 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_18 = pd.merge(df_A, df_B, how='inner').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "res_sql_18.shape, res_pd_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ebc40-e0f0-4108-995b-328a2ee2f5ce",
   "metadata": {},
   "source": [
    "**Zadanie 19**\n",
    "Rozwiąż zadanie na dwa sposoby: wykonując odpowiednie zapytanie SQL oraz operacje na ramkach danych.\n",
    "\n",
    "Wyznacz tylko te rekordy z `A`, których nie ma w `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM A EXCEPT SELECT * FROM B\")\n",
    "    res_sql_19 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "merged_df = pd.merge(df_A, df_B, how='left', indicator=True)\n",
    "res_pd_19 = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge']).reset_index(drop=True)\n",
    "\n",
    "res_sql_19.shape, res_pd_19.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d08991-29d1-4ee7-a7c9-44c3b0a111b1",
   "metadata": {},
   "source": [
    "**Zadanie 20**\n",
    "Złącz ramkę danych `flights` z ramką `planes`. Wybierz najbardziej odpowiedni rodzaj złączenia oraz kolumny biorące w nim udział. Wykonaj zadanie z wykorzystaniem zapytania SQL oraz na ramkach danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b14265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT f.*, p.year as p_year, p.type, p.manufacturer\n",
    "        FROM flights f\n",
    "        LEFT JOIN planes p ON f.tailnum = p.tailnum\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    res_sql_20 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_20 = flights.merge(planes, on='tailnum', how='left').head(5)\n",
    "\n",
    "res_sql_20.head(), res_pd_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc104582-6d3a-48bf-b86a-6bfbc61e6f7a",
   "metadata": {},
   "source": [
    "**Zadanie 21**\n",
    "Złącz ramkę danych `flights` z ramką `airports`. Wykonaj zadanie z wykorzystaniem zapytania SQL oraz na ramkach danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0297e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT f.*, a.name as dest_name\n",
    "        FROM flights f\n",
    "        LEFT JOIN airports a ON f.dest = a.faa\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    res_sql_21 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_21 = flights.merge(airports, left_on='dest', right_on='faa', how='left').head(5)\n",
    "\n",
    "res_sql_21.head(), res_pd_21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23b218-323f-453b-a9a6-89b17a6c2319",
   "metadata": {},
   "source": [
    "**Zadanie 22**\n",
    "Złącz ramkę danych `flights` z ramką `weather`. Wykonaj zadanie z wykorzystaniem zapytania SQL oraz na ramkach danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87cb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT f.*, w.temp, w.humid\n",
    "        FROM flights f\n",
    "        LEFT JOIN weather w \n",
    "        ON f.origin = w.origin AND f.year = w.year AND f.month = w.month AND f.day = w.day AND f.hour = w.hour\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    res_sql_22 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "join_cols = ['origin', 'year', 'month', 'day', 'hour']\n",
    "res_pd_22 = flights.merge(weather, on=join_cols, how='left').head(5)\n",
    "\n",
    "res_sql_22.head(), res_pd_22.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206bcb6-9392-47b5-8522-feadeeb43040",
   "metadata": {},
   "source": [
    "**Zadanie 23**\n",
    "Złącz ramkę danych `flights` z ramkami `weather`, `planes` oraz `airport`. Wykonaj zadanie z wykorzystaniem zapytania SQL oraz na ramkach danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac990635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# SQL\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"\"\"\n",
    "        SELECT f.*, p.manufacturer, a.name as airport, w.temp\n",
    "        FROM flights f\n",
    "        LEFT JOIN planes p ON f.tailnum = p.tailnum\n",
    "        LEFT JOIN airports a ON f.dest = a.faa\n",
    "        LEFT JOIN weather w \n",
    "        ON f.origin = w.origin AND f.year = w.year AND f.month = w.month AND f.day = w.day AND f.hour = w.hour\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    res_sql_23 = pd.read_sql(query, conn)\n",
    "\n",
    "# Pandas\n",
    "res_pd_23 = (\n",
    "    flights\n",
    "    .merge(planes[['tailnum', 'manufacturer']], on='tailnum', how='left')\n",
    "    .merge(airports[['faa', 'name']], left_on='dest', right_on='faa', how='left')\n",
    "    .merge(weather[['origin', 'year', 'month', 'day', 'hour', 'temp']], on=['origin', 'year', 'month', 'day', 'hour'], how='left')\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "res_sql_23.head(), res_pd_23.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63795ca8-85de-4810-83f9-c5dd7eb975f5",
   "metadata": {},
   "source": [
    "**Zadanie 24**\n",
    "Plik *game.xlsx* zawiera dane o gach planszowych, odczytaj dane z pliku i załaduj do `DataFrame`. Zwróć uwagę na braki danych, które mogą występować w pliku. Po odczytaniu danych znajdź kolumnę, w której występuje najwięcej braków danych i usuń ją. Dane po oczyszczeniu zapisz do pliku *games.xml* nadając nazwę korzeniowi `games` a każdemu rekordowi `game`..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78136acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df_games = pd.read_excel('game.xlsx')\n",
    "    \n",
    "    # Znalezienie kolumny z najwieksza liczba brakow\n",
    "    na_counts = df_games.isna().sum()\n",
    "    drop_col = na_counts.idxmax()\n",
    "    \n",
    "    # Usuniecie i zapis\n",
    "    df_clean = df_games.drop(columns=[drop_col])\n",
    "    df_clean.to_xml('games.xml', root_name='games', row_name='game', index=False)\n",
    "    \n",
    "    print(f\"Usunięto kolumnę: {drop_col}\")\n",
    "    print(\"Plik games.xml zapisany.\")\n",
    "except Exception as err:\n",
    "    print(f\"Wystąpił błąd: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a6cf5-1c06-4c5c-9c7a-45ef1e7a1fd0",
   "metadata": {},
   "source": [
    "**Zadanie 25**\n",
    "Skorzystaj z pliku `games.xml`, który został stworzony w poprzednim zadaniu i wczytaj dane do ramki danych. Następnie posortuj po kolumnie `year` w porządku rosnącym i załaduj dane do utworzonej bazy danych sqlite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24190532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Wczytanie z XML\n",
    "    df_xml = pd.read_xml('games.xml')\n",
    "    \n",
    "    # Sortowanie\n",
    "    df_sorted = df_xml.sort_values('year')\n",
    "    \n",
    "    # Zapis do bazy\n",
    "    df_sorted.to_sql('games', con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"Dane posortowane i zapisane do bazy.\")\n",
    "    print(df_sorted.head())\n",
    "except Exception as err:\n",
    "    print(f\"Błąd: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0e4c1-5af0-4028-98f4-1548a62a8c3a",
   "metadata": {},
   "source": [
    "**Zadanie 26**\n",
    "Folder *city* zawiera pliki o rozszerzeniach _*.xlsx_, _*.csv_, _*.xml_. Każdy plik reprezentuje osobne miasto i zawiera dane pogodowe. Napisz rozwiązanie, które odczyta następujące kolumny `time`, `temperature_2m_mean`, `daylight_duration`, `rain_sum`, `snowfall_sum`, `wind_speed_10m_max`, `wind_direction_10m_dominant` i połącz je w jedną ramkę danych. Dodając dane do wspólnej ramki danych dodaj nową kolumnę `city_id`, która będzie odpowiadać numerowi miasta. Dane zapisz w dwóch plikach ``weather.jso`` (dane pogodowe) oraz `city_key.jso`  (miasta z numerami id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blad przy pliku Gdansk.xlsx: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "Blad przy pliku Krakow.xlsx: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "Blad przy pliku Poznan.xlsx: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "Zapisano weather.jso i city_key.jso\n",
      "         time  temperature_2m_mean  daylight_duration  rain_sum  snowfall_sum  \\\n",
      "0  2024-09-16                 18.3           45255.84       0.0           0.0   \n",
      "1  2024-09-17                 18.0           45020.50       0.0           0.0   \n",
      "2  2024-09-18                 16.9           44784.85       1.3           0.0   \n",
      "3  2024-09-19                 15.7           44549.05       0.0           0.0   \n",
      "4  2024-09-20                 13.9           44313.21       0.0           0.0   \n",
      "\n",
      "   wind_speed_10m_max  wind_direction_10m_dominant  city_id  \n",
      "0                24.7                           68        1  \n",
      "1                16.4                           72        1  \n",
      "2                12.3                           62        1  \n",
      "3                20.1                           80        1  \n",
      "4                14.9                           89        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = 'city'\n",
    "weather_list = []\n",
    "cities_map = []\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    cid = 1\n",
    "    \n",
    "    for filename in file_list:\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # Wczytywanie w zaleznosci od rozszerzenia\n",
    "            if filename.endswith('.xlsx'):\n",
    "                temp_df = pd.read_excel(full_path)\n",
    "            elif filename.endswith('.csv'):\n",
    "                temp_df = pd.read_csv(full_path)\n",
    "            elif filename.endswith('.xml'):\n",
    "                temp_df = pd.read_xml(full_path)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            required_cols = ['time', 'temperature_2m_mean', 'daylight_duration', 'rain_sum', 'snowfall_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']\n",
    "            \n",
    "            # Sprawdzenie kolumn\n",
    "            if set(required_cols).issubset(temp_df.columns):\n",
    "                sub_df = temp_df[required_cols].copy()\n",
    "                sub_df['city_id'] = cid\n",
    "                weather_list.append(sub_df)\n",
    "                \n",
    "                c_name = os.path.splitext(filename)[0]\n",
    "                cities_map.append({'city_id': cid, 'city_name': c_name})\n",
    "                \n",
    "                cid += 1\n",
    "        except Exception as ex:\n",
    "            print(f\"Problem z plikiem {filename}: {ex}\")\n",
    "    \n",
    "    if weather_list:\n",
    "        final_df = pd.concat(weather_list, ignore_index=True)\n",
    "        final_df.to_json('weather.jso', orient='records')\n",
    "        \n",
    "        with open('city_key.jso', 'w') as json_file:\n",
    "            json.dump(cities_map, json_file)\n",
    "            \n",
    "        print(\"Pliki weather.jso oraz city_key.jso zostały utworzone.\")\n",
    "        print(final_df.head())\n",
    "    else:\n",
    "        print(\"Nie znaleziono pasujących danych.\")\n",
    "else:\n",
    "    print(f\"Katalog {folder_path} nie został znaleziony.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
